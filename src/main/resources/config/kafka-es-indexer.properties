### Zookeeper properties ####################################
# Zookeeper's host:port list: <host1>:<port1>,…,<hostN>:<portN>
# default value: localhost:2181, if not specified
kafkaZookeeperList=lvsdmetl43.lvs.paypal.com:2181,lvsdmetl44.lvs.paypal.com:2181,lvsdmetl45.lvs.paypal.com:2181,lvsdmetl46.lvs.paypal.com:2181,lvsdmetl47.lvs.paypal.com:2181

# Zookeeper session timeout in MS
zkSessionTimeoutMs=10000

# Zookeeper connection timeout in MS
zkConnectionTimeoutMs=15000

# Zookeeper number of retries when creating a curator client
zkCuratorRetryTimes=3

# Zookeeper: time in ms between re-tries when creating a Curator
zkCuratorRetryDelayMs=2000

### Kafka properties ####################################
kafkaBrokersList=lvsdmetl48.lvs.paypal.com:9092,lvsdmetl49.lvs.paypal.com:9092,lvsdmetl50.lvs.paypal.com:9092,lvsdmetl51.lvs.paypal.com:9092,lvsdmetl52.lvs.paypal.com:9092,lvsdmetl53.lvs.paypal.com:9092,lvsdmetl54.lvs.paypal.com:9092,lvsdmetl55.lvs.paypal.com:9092

# Kafka Consumer group name prefix - 
# each indexer job will have a clientId = consumerGroupName + "_" + partitionNumber
# default: kafka_es_indexer
consumerGroupName=kafka_es_indexer

# Kafka Topic from which the message has to be processed
# mandatory property, no default value specified.
topic=system

## below two properties define a range of partitions to be processed by this application;
## each partition will be processed by an IndexerJob in a separate Thread, so this also
## defines the number of indexer threads created by the app - please set memory requirements accordingly

# first partition in the Kafka's Topic(defined by 'topic' property) to process messages from
# default: 0
firstPartition=0

# last partition in the Kafka's Topic(defined by 'topic' property) to process messages from
# no default - is required
lastPartition=9

# Offset option from where the message fetching should happen in kafka
# Values can be: CUSTOM / EARLIEST / LATEST / RESTART.
# CUSTOM:  Message from the specified(defined by 'startOffset' property) offset in Kafka will be read. If 'CUSTOM' is set, then 'startOffset' property has to be set an integer value
# EARLIEST:  Messages from the earliest available offset in kafka will be read
# LATEST:  Messages from the latest available offset in kafka will be read
# RESTART: Message reading will happen from the Offset where the last cycle of reading by this client has stopped
# Default:"EARLIEST"
startOffsetFrom=RESTART

# integer value of the offset from where the message processing should happen. Use this property in conjunction with 'startOffsetFrom=CUSTOM'
# mandatory property when 'startOffsetFrom' is set to 'CUSTOM', no default value specified.
startOffset=0

# Kafka FetchRequest's minBytes value 
# Default: "31457280(bytes), i.e:(10 * 1024 * 1024 * 3)"
# Set it to ~4MB and slowly rampup based in your heap memory.
# setting this value to more than 31457280 may cause errors from batch indexing call to ES
# and in some cases this causes the indexer job to hang 
kafkaFetchSizeMinBytes=31457280

# Kafka SimpleConsumer socket bufferSize
kafkaSimpleConsumerBufferSizeBytes=31457280
# Kafka SimpleConsumer socket timeout in MS
kafkaSimpleConsumerSocketTimeoutMs=10000

# timeout in seconds before force-stopping Indexer app and all indexer jobs
appStopTimeoutSeconds=10

# number of times to try to re-init Kafka connections/consumer if read/write to Kafka fails
numberOfReinitTries=2
# sleep time in ms between Kafka re-init attempts
kafkaReinitSleepTimeMs=10000

### ElasticSearch properties ####################################
# ElasticSearch Host and Port List for all the nodes
#esHostPortList=lvshdc2en0018.lvs.paypal.com-node0:9300,lvshdc2en0018.lvs.paypal.com-node1:9301,lvshdc2en0018.lvs.paypal.com-node2:9302,lvshdc2en0018.lvs.paypal.com-node3:9303,lvshdc2en0019.lvs.paypal.com-node0:9300,lvshdc2en0019.lvs.paypal.com-node1:9301,lvshdc2en0019.lvs.paypal.com-node2:9302,lvshdc2en0019.lvs.paypal.com-node3:9303,lvshdcpba001-node0:9300,lvshdcpba001-node1:9301,lvshdcpba001-node2:9302,lvshdcpba001-node3:9303,lvshdcpba002-node0:9300,lvshdcpba002-node1:9301,lvshdcpba002-node2:9302,lvshdcpba002-node3:9303,lvshdcpba003-node0:9300,lvshdcpba003-node1:9301,lvshdcpba003-node2:9302,lvshdcpba003-node3:9303,lvshdcpba004-node0:9301,lvshdcpba004-node1:9300,lvshdcpba004-node2:9302,lvshdcpba004-node3:9303,lvshdcpba014-node0:9301,lvshdcpba014-node1:9300,lvshdcpba014-node2:9302,lvshdcpba014-node3:9303
esHostPortList=lvshdcpba001.lvs.paypal.com:9300

# Name of the ElasticSearch Cluster that messages will be posted to;
# Tip: Its not a good idea to use the default name "ElasticSearch" as your cluster name. 
esClusterName=hadoop

# ES Index Name that messages will be posted/indexed to; this can be customized via using a custom IndexHandler implementation class
# Default: "kafkaESIndex"
esIndexName=tahoe-spark-kafka-index

# ES Index Type that messages will be posted/indexed to; this can be customized via using a custom IndexHandler implementation class 
# Default: “kafkaESType” 
esIndexType=system_topic

# Fully qualified name of a concrete message handler class
# Default: "org.elasticsearch.kafka.consumer.RawMessageStringHandler"
# Custom class should be extended from org.elasticsearch.kafka.consumer.MessageHandler class
messageHandlerClass=org.elasticsearch.kafka.indexer.messageHandlers.RawMessageStringHandler

# Fully qualified name of a custom IndexHandler implementation class
# Default: org.elasticsearch.kafka.consumer.BasicIndexHandler
indexHandlerClass=org.elasticsearch.kafka.indexer.BasicIndexHandler


# Preferred message encoding to process the message before posting it to ElasticSearch.
# Default: "UTF-8" 
messageEncoding=UTF-8

# Dry runs will not post to elasticsearch and won’t commit the offset to Kafka
isDryRun=false

# Time in ms for the consumer to sleep between each round of reading events from Kafka
consumerSleepBetweenFetchsMs=1000
# number of times to try to re-connect to ES when performing batch indexing , if connection to ES fails
numberOfEsIndexingRetryAttempts=2
# sleep time in ms between attempts to connect to ES
esIndexingRetrySleepTimeMs=10000

# flag to enable/disable performance timings reporting; Set it to true when performance/load-testing your app, set to ‘false’ when deploying in production as it will affect performance of the app; defaults to ‘false'
isPerfReportingEnabled=false

